{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Copyright Â© 2021, SAS Institute Inc., Cary, NC, USA.  All Rights Reserved.\n",
    "SPDX-License-Identifier: Apache-2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# HMEQ Dataset : Build and Import Trained Models into SAS Model Manager\n",
    "\n",
    "This notebook provides an example of how to build and train a simple Python model and then import the model into SAS Model Manager using the HMEQ data set. Lines of code that must be modified by the user, such as directory paths or the host server are noted with the comment \"_Changes required by user._\".\n",
    "\n",
    "_**Note:** If you download only this notebook and not the rest of the repository, you must also download the hmeq.csv file from the data folder in the examples directory. These files are used when executing this notebook example._\n",
    "\n",
    "Here are the steps shown in this notebook:\n",
    "\n",
    "1. Import, review, and preprocess data for model training.\n",
    "2. Build, train, and assess a scikit-learn decision tree, random forest, and gradient boosting model.\n",
    "3. Serialize the models into separate pickle files.\n",
    "4. Write the metadata JSON files needed for importing into SAS Model Manager as well as optional files for fit statistics and ROC/Lift charts.\n",
    "4. Write a score code Python file for model scoring.\n",
    "5. Zip the pickle, JSON, and score code files into an archive file.\n",
    "6. Import the ZIP archive file to SAS Model Manager via the Session object and relevant function call."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Python Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "# Third Party\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Application Specific\n",
    "import sasctl.pzmm as pzmm\n",
    "from sasctl import Session\n",
    "\n",
    "# Global Package Options\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "plt.rc(\"font\", size=14)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Import and Review Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeqData = pd.read_csv('data/hmeq.csv',sep= ',')\n",
    "hmeqData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeqData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeqData.hist(figsize=(15,15), layout=(4, 4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "hmeqData.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predictorColumns = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']\n",
    "\n",
    "targetColumn = 'BAD'\n",
    "x = hmeqData[predictorColumns]\n",
    "y = hmeqData[targetColumn]\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# For missing values, impute the data set's mean value\n",
    "xTest.fillna(xTest.mean(), inplace=True)\n",
    "xTrain.fillna(xTrain.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Create, Train, and Assess Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "treeModel = DecisionTreeClassifier(random_state=42)\n",
    "treeModel = treeModel.fit(xTrain, yTrain)\n",
    "\n",
    "forestModel = RandomForestClassifier(random_state=42)\n",
    "forestModel = forestModel.fit(xTrain, yTrain)\n",
    "\n",
    "gradientModel = GradientBoostingClassifier(random_state=42)\n",
    "gradientModel = gradientModel.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def sortFeatureImportance(model, xData):\n",
    "    features = {}\n",
    "    for importance, name in sorted(zip(model.feature_importances_, xData.columns), reverse=True):\n",
    "        features[name] = str(np.round(importance*100, 2)) + '%'\n",
    "    return features\n",
    "\n",
    "importances = pd.DataFrame.from_dict(sortFeatureImportance(treeModel, xTrain), orient='index').rename(columns={0: 'DecisionTree'})\n",
    "importances['RandomForest'] = pd.DataFrame.from_dict(sortFeatureImportance(forestModel, xTrain), orient='index')\n",
    "importances['GradientBoosting'] = pd.DataFrame.from_dict(sortFeatureImportance(gradientModel, xTrain), orient='index')\n",
    "importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "yTreePredict = treeModel.predict(xTest)\n",
    "yTreeProba = treeModel.predict_proba(xTest)\n",
    "print(confusion_matrix(yTest, yTreePredict))\n",
    "print(classification_report(yTest, yTreePredict))\n",
    "print('Decision Tree Model Accuracy = ' + str(np.round(treeModel.score(xTest, yTest)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "yForestPredict = forestModel.predict(xTest)\n",
    "yForestProba = forestModel.predict_proba(xTest)\n",
    "print(confusion_matrix(yTest, yForestPredict))\n",
    "print(classification_report(yTest, yForestPredict))\n",
    "print('Random Forest Model Accuracy = ' + str(np.round(forestModel.score(xTest, yTest)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yGradientPredict = gradientModel.predict(xTest)\n",
    "yGradientProba = gradientModel.predict_proba(xTest)\n",
    "print(confusion_matrix(yTest, yGradientPredict))\n",
    "print(classification_report(yTest, yGradientPredict))\n",
    "print('Gradient Boosting Model Accuracy = ' + str(np.round(gradientModel.score(xTest, yTest)*100,2)) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Register Model in SAS Model Manager with pzmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "modelPrefix = ['DecisionTreeClassifier', 'RandomForest', 'GradientBoosting']\n",
    "zipFolder = [Path.cwd() / 'data/hmeqModels/DecisionTreeClassifier/',\n",
    "             Path.cwd() / 'data/hmeqModels/RandomForest/',\n",
    "             Path.cwd() / 'data/hmeqModels/GradientBoosting'] # User created directories\n",
    "model = [treeModel, forestModel, gradientModel]\n",
    "\n",
    "for (m, prefix, path) in zip(model, modelPrefix, zipFolder):\n",
    "    pzmm.PickleModel.pickle_trained_model(m, prefix, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def writeJSONFiles(data, predict, target, zipFolder, modelPrefix):\n",
    "    J = pzmm.JSONFiles()\n",
    "    \n",
    "    # Write input variable mapping to a json file\n",
    "    J.writeVarJSON(data[predict], isInput=True, jPath=zipFolder)\n",
    "    \n",
    "    # Set output variables and assign an event threshold, then write output variable mapping\n",
    "    outputVar = pd.DataFrame(columns=['EM_EVENTPROBABILITY', 'EM_CLASSIFICATION'], data=[[0.5, 'A']]) # data argument includes example expected types for columns\n",
    "    J.writeVarJSON(outputVar, isInput=False, jPath=zipFolder)\n",
    "    \n",
    "    # Write model properties to a json file\n",
    "    J.writeModelPropertiesJSON(modelName=modelPrefix,\n",
    "                               modelDesc='',\n",
    "                               targetVariable=target,\n",
    "                               modelType='',\n",
    "                               modelPredictors=predict,\n",
    "                               targetEvent=1,\n",
    "                               numTargetCategories=1,\n",
    "                               eventProbVar='EM_EVENTPROBABILITY',\n",
    "                               jPath=zipFolder,\n",
    "                               modeler='sasdemo')\n",
    "    \n",
    "    # Write model metadata to a json file\n",
    "    J.writeFileMetadataJSON(modelPrefix, jPath=zipFolder)\n",
    "\n",
    "for (prefix, path) in zip(modelPrefix, zipFolder):\n",
    "    writeJSONFiles(hmeqData, predictorColumns, targetColumn, path, prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import getpass\n",
    "def writeModelStats(xTrain, yTrain, testProba, yTest, model, target, zipFolder, conn):\n",
    "    J = pzmm.JSONFiles()\n",
    "    \n",
    "    # Calculate train predictions\n",
    "    trainProba = model.predict_proba(xTrain)\n",
    "    \n",
    "    # Assign data to lists of actual and predicted values\n",
    "    trainData = pd.concat([yTrain.reset_index(drop=True), pd.Series(data=trainProba[:,1])], axis=1)\n",
    "    testData = pd.concat([yTest.reset_index(drop=True), pd.Series(data=testProba[:,1])], axis=1)\n",
    "    \n",
    "    # Calculate the model statistics and write to json files\n",
    "    J.calculateFitStat(trainData=trainData, testData=testData, jPath=zipFolder)\n",
    "    J.generateROCLiftStat(target, 1, conn, trainData=trainData, testData=testData, jPath=zipFolder)\n",
    "    \n",
    "username = getpass.getpass()\n",
    "password = getpass.getpass()\n",
    "host = 'demo.sas.com'\n",
    "sess = Session(host, username, password, protocol='http')\n",
    "conn = sess.as_swat()\n",
    "\n",
    "testProba = [yTreeProba, yForestProba, yGradientProba]\n",
    "for (m, proba, path) in zip(model, testProba, zipFolder):\n",
    "    writeModelStats(xTrain, yTrain, proba, yTest, m, targetColumn, path, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "I = pzmm.ImportModel()\n",
    "for (prefix, path) in zip(modelPrefix, zipFolder):\n",
    "    I.pzmmImportModel(path, prefix, 'HMEQModels', x, y, '{}.predict({})', force=True)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f9708d3f38eeab835578f0695c8890716ee809285281a28db6e379a5abca1310"
  },
  "kernelspec": {
   "display_name": "dev-py38",
   "language": "python",
   "name": "dev-py38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
